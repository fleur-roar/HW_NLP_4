{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## HW NLP\n",
        "### Кластеризация контекстов неоднозначных слов\n",
        "#### Ревак Ксения"
      ],
      "metadata": {
        "id": "_3HgsvhUb5W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пункт 1. Сбор данных - ручной (основные значения)\n",
        "\n"
      ],
      "metadata": {
        "id": "aCQGbia1cRIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Были выбраны следующие неоднозначные слова:  \n",
        "   \n",
        "**Лук**, **Коса**, **Замок**, **Кран**, **Язык**.  \n",
        "  \n",
        "  \n",
        "Определения в словарях (были взяты немного в упрощенном варианте, чтобы не распыляться на множество очень близких значений типа лук - 1)огородное растение 2) съедобные части этого растения - ну что это такое, хочется увидеть реальное разделение значений):  \n",
        "  \n",
        "**Лук** (омонимы)  _Толковый словарь Ефремовой_  \n",
        "1. Луковичное растение семейства лилейных.\n",
        "2. Ручное оружие для метания стрел в виде дуги, стянутой тетивой.\n",
        "\n",
        "**Коса**  (омонимы) _Толковый словарь Ефремовой_   \n",
        " 1. Несколько прядей волос на голове человека, сплетенные вместе.\n",
        " 2. Сельскохозяйственное орудие в виде узкого изогнутого лезвия, насаженного на длинную рукоятку, служащее для срезывания травы, хлебных злаков.\n",
        " 3. Длинная узкая отмель, идущая от берега; мыс.\n",
        "\n",
        "**Замок** (омографы)  _Толковый словарь Ефремовой_   \n",
        "1. Укрепленное жилище - дворец и крепость - феодала.\n",
        "2. 1) а) Устройство для запирания дверей, чемоданов, ящиков мебели и т.п. ключом, б) Приспособление для соединения концов ювелирных изделий (ожерелья, браслета, цепочки и т.п.).  \n",
        "  2) Способ соединения бревен, брусьев, при котором они составляют одно целое.\n",
        "\n",
        "**Кран** (многозначное)  _Толковый словарь Ефремовой_   \n",
        "1. Устройство для выпуска жидкости или газа из резервуара или трубопровода; трубопроводный вентиль.  \n",
        "2. Устройство для управления тормозной системой подвижного железнодорожного состава.  \n",
        "3. Механизм для подъема и перемещения грузов.\n",
        "  \n",
        "**Язык** (многозначное)    _Толковый словарь Ефремовой_   \n",
        "1. Подвижный мышечный орган в ротовой полости позвоночных животных и человека, способствующий захватыванию, пережевыванию и т.п. пищи. + перен. металлический стержень в колоколе.\n",
        "\n",
        "2. Исторически сложившаяся система словесного выражения мыслей, обладающая определенным звуковым, лексическим и грамматическим строем и служащая средством общения в человеческом обществе.\n",
        "\n",
        "3. разг. Противник, взятый в плен с целью получить необходимые сведения."
      ],
      "metadata": {
        "id": "wqEHIr6acfWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пункт 1,5. Сбор данных краулингом - со всеми тонкостями."
      ],
      "metadata": {
        "id": "AEMtZX-QTG_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "#url = f\"https://gufo.me/dict/ozhegov/{word}?ysclid=lpumzv7p9d627750059\""
      ],
      "metadata": {
        "id": "NeKXUTWyT_5a"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.efremova.info/word/luk.html\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    print(soup)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0pa6f86UqcK",
        "outputId": "c452c2f4-1b7d-4a83-9298-7b01f696afeb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\r\n",
            "        \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n",
            "\n",
            "<html lang=\"ru\" xml:lang=\"ru\" xmlns=\"http://www.w3.org/1999/xhtml\">\n",
            "<head>\n",
            "<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\n",
            "<title>Лук, значения слова / Толковый словарь Ефремовой</title>\n",
            "<meta content=\"Значение слова лук в толковом словаре\" name=\"Description\"/>\n",
            "<meta content=\"index, follow\" name=\"Robots\"/>\n",
            "<meta content=\"264af7952430bb92\" name=\"yandex-verification\"/>\n",
            "<script src=\"/js/tooltips.js\" type=\"text/javascript\"></script>\n",
            "<script src=\"/js/cl.js\" type=\"text/javascript\"></script>\n",
            "<link href=\"/css/styles.css\" rel=\"stylesheet\" type=\"text/css\"/>\n",
            "<link href=\"/favicon.ico\" rel=\"icon\" type=\"image/x-icon\"/>\n",
            "<link href=\"/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\"/>\n",
            "</head>\n",
            "<body>\n",
            "<div id=\"header\">\n",
            "<div class=\"topBanner\">\n",
            "</div>\n",
            "<a href=\"/\" id=\"logo\">\n",
            "<span>Толковый словарь русского языка Ефремовой</span>\n",
            "</a>\n",
            "</div>\n",
            "<div id=\"main\">\n",
            "<table>\n",
            "<tr>\n",
            "<td id=\"leftCnt\">\n",
            "<div class=\"infoBlock\">\n",
            "<div class=\"contents\">\n",
            "<h3>Поиск в словаре</h3>\n",
            "<form action=\"/search/\" method=\"get\" name=\"search\">\n",
            "<div>\n",
            "<input name=\"cx\" type=\"hidden\" value=\"partner-pub-9930840937960329:6051420664\"/>\n",
            "<input name=\"cof\" type=\"hidden\" value=\"FORID:10\"/>\n",
            "<input name=\"ie\" type=\"hidden\" value=\"UTF-8\"/>\n",
            "</div>\n",
            "<div><input class=\"search\" name=\"q\" type=\"text\"/></div>\n",
            "<div class=\"sbutton\">\n",
            "<input class=\"bsearch\" onclick=\"document.search.submit()\" type=\"button\" value=\"Найти\"/>\n",
            "</div>\n",
            "</form>\n",
            "</div>\n",
            "</div>\n",
            "<div class=\"infoBlock\">\n",
            "<div class=\"contents\">\n",
            "<div class=\"letters wrp\">\n",
            "<h3>Алфавитный указатель</h3>\n",
            "<ul>\n",
            "<li><a href=\"/letter/+a.html\">А</a></li>\n",
            "<li><a href=\"/letter/+b.html\">Б</a></li>\n",
            "<li><a href=\"/letter/+v.html\">В</a></li>\n",
            "<li><a href=\"/letter/+g.html\">Г</a></li>\n",
            "<li><a href=\"/letter/+d.html\">Д</a></li>\n",
            "<li><a href=\"/letter/+e.html\">Е</a></li>\n",
            "<li><a href=\"/letter/+jo.html\">Ё</a></li>\n",
            "<li><a href=\"/letter/+zh.html\">Ж</a></li>\n",
            "<li><a href=\"/letter/+z.html\">З</a></li>\n",
            "<li><a href=\"/letter/+i.html\">И</a></li>\n",
            "<li><a href=\"/letter/+jj.html\">Й</a></li>\n",
            "<li><a href=\"/letter/+k.html\">К</a></li>\n",
            "<li><a href=\"/letter/+l.html\">Л</a></li>\n",
            "<li><a href=\"/letter/+m.html\">М</a></li>\n",
            "<li><a href=\"/letter/+n.html\">Н</a></li>\n",
            "<li><a href=\"/letter/+o.html\">О</a></li>\n",
            "<li><a href=\"/letter/+p.html\">П</a></li>\n",
            "<li><a href=\"/letter/+r.html\">Р</a></li>\n",
            "<li><a href=\"/letter/+s.html\">С</a></li>\n",
            "<li><a href=\"/letter/+t.html\">Т</a></li>\n",
            "<li><a href=\"/letter/+u.html\">У</a></li>\n",
            "<li><a href=\"/letter/+f.html\">Ф</a></li>\n",
            "<li><a href=\"/letter/+kh.html\">Х</a></li>\n",
            "<li><a href=\"/letter/+c.html\">Ц</a></li>\n",
            "<li><a href=\"/letter/+ch.html\">Ч</a></li>\n",
            "<li><a href=\"/letter/+sh.html\">Ш</a></li>\n",
            "<li><a href=\"/letter/+shh.html\">Щ</a></li>\n",
            "<li><a href=\"#\">Ъ</a></li>\n",
            "<li><a href=\"/letter/+y.html\">Ы</a></li>\n",
            "<li><a href=\"/letter/+'.html\">Ь</a></li>\n",
            "<li><a href=\"/letter/+eh.html\">Э</a></li>\n",
            "<li><a href=\"/letter/+ju.html\">Ю</a></li>\n",
            "<li><a href=\"/letter/+ja.html\">Я</a></li>\n",
            "</ul>\n",
            "</div>\n",
            "</div>\n",
            "</div>\n",
            "<div class=\"infoBlock\">\n",
            "<div class=\"contents\">\n",
            "<!-- efrem-160 -->\n",
            "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-6722709838876624\" data-ad-slot=\"2615081161\" style=\"display:inline-block;width:160px;height:600px\"></ins>\n",
            "<script>\r\n",
            "     (adsbygoogle = window.adsbygoogle || []).push({});\r\n",
            "</script>\n",
            "</div>\n",
            "</div>\n",
            "<div class=\"infoBlock\">\n",
            "<div class=\"contents\">\n",
            "<h3>Статистика слов</h3>\n",
            "<p class=\"last\">Общее количество значений слов: 123,170</p>\n",
            "</div>\n",
            "</div>\n",
            "</td>\n",
            "<td id=\"centerCnt\">\n",
            "<div class=\"path\">\n",
            "<ul><li class=\"home\"><a href=\"/\">Толковый словарь</a></li><li><a href=\"/letter/+l.html\">Список на букву «л»</a></li><li><a href=\"/letter/+lu.html\">Список слов начинающихся с «лу»</a></li><li><strong>Значение слова «Лук»</strong></li></ul> </div>\n",
            "<!-- -->\n",
            "<h1>Значение слова лук</h1>\n",
            "<div align=\"left\">\n",
            "<!-- efrem-336 -->\n",
            "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-6722709838876624\" data-ad-format=\"auto\" data-ad-slot=\"8005324433\" data-full-width-responsive=\"true\" style=\"display:block\"></ins>\n",
            "<script>\r\n",
            "     (adsbygoogle = window.adsbygoogle || []).push({});\r\n",
            "</script>\n",
            "</div>\n",
            "<div>\n",
            "<div class=\"descr\"><ol><li><a name=\"o1\"></a> <em><acronym title=\"мужской (род)\">м.</acronym></em>\n",
            "<ol><li> </li> <ol><li>Огородное растение семейства лилейных.\r\n",
            " <li>Съедобные части такого огородного растения.</li></li></ol><li><a name=\"so2\"></a>Дикорастущее травянистое луковичное растение семейства лилейных.</li></ol><li><a name=\"o2\"></a> <div class=\"type\"><em><acronym title=\"мужской (род)\">м.</acronym></em></div>\n",
            "<ol><li><a name=\"so1\"></a>Ручное оружие для метания стрел в виде дуги, стянутой тетивой.</li></ol></li></li></ol></div> </div>\n",
            "<!-- AddThis Button BEGIN -->\n",
            "<div id=\"item-share\">\n",
            "<div class=\"addthis_toolbox addthis_default_style addthis_32x32_style\">\n",
            "<a class=\"addthis_button_vk\"></a>\n",
            "<a class=\"addthis_button_facebook\"></a>\n",
            "<a class=\"addthis_button_odnoklassniki_ru\"></a>\n",
            "<a class=\"addthis_button_twitter\"></a>\n",
            "<a class=\"addthis_button_google_plusone_share\"></a>\n",
            "</div>\n",
            "<script type=\"text/javascript\">var addthis_config = {\"data_track_addressbar\": true};</script>\n",
            "<script src=\"//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-526274961c7820b0\" type=\"text/javascript\"></script>\n",
            "<!-- AddThis Button END -->\n",
            "<p id=\"see-also\">\r\n",
            "        Смотрите также <strong>толкование слова лук</strong> в:\r\n",
            "        <a href=\"https://www.google.ru/search?q=define%3A%D0%BB%D1%83%D0%BA\" target=\"_blank\">Google</a>,\r\n",
            "        <a href=\"https://ru.wiktionary.org/w/index.php?title=Служебная%3ASearch&amp;search=%D0%BB%D1%83%D0%BA\" target=\"_blank\">Википедия</a>\n",
            "</p>\n",
            "</div>\n",
            "<div style=\"margin-top: 2em\">\n",
            "<script async=\"\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js\"></script>\n",
            "<!-- После слова -->\n",
            "<ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-6722709838876624\" data-ad-format=\"auto\" data-ad-slot=\"2311828837\" data-full-width-responsive=\"true\" style=\"display:block\"></ins>\n",
            "<script>\r\n",
            "     (adsbygoogle = window.adsbygoogle || []).push({});\r\n",
            "</script>\n",
            "</div>\n",
            "</td>\n",
            "</tr>\n",
            "</table>\n",
            "</div>\n",
            "<!-- Global site tag (gtag.js) - Google Analytics -->\n",
            "<script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=UA-113309419-1\"></script>\n",
            "<script>\r\n",
            "    window.dataLayer = window.dataLayer || [];\r\n",
            "    function gtag(){dataLayer.push(arguments);}\r\n",
            "    gtag('js', new Date());\r\n",
            "    gtag('config', 'UA-113309419-1');\r\n",
            "</script>\n",
            "<div id=\"footer\">\n",
            "<div class=\"copy\">\n",
            "<p>2005–2021 Толковый словарь Ефремовой <a href=\"https://www.cebiz.org\">1xbet</a> и <a href=\"https://hcneftekhimik.ru/\">1win</a></p>\n",
            "</div>\n",
            "</div>\n",
            "</body>\n",
            "<!-- Yandex.Metrika counter -->\n",
            "<script type=\"text/javascript\">\r\n",
            "   (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};\r\n",
            "   m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})\r\n",
            "   (window, document, \"script\", \"https://mc.yandex.ru/metrika/tag.js\", \"ym\");\r\n",
            "\r\n",
            "   ym(86391606, \"init\", {\r\n",
            "        clickmap:true,\r\n",
            "        trackLinks:true,\r\n",
            "        accurateTrackBounce:true\r\n",
            "   });\r\n",
            "</script>\n",
            "<noscript><div><img alt=\"\" src=\"https://mc.yandex.ru/watch/86391606\" style=\"position:absolute; left:-9999px;\"/></div></noscript>\n",
            "<!-- /Yandex.Metrika counter -->\n",
            "</html><!-- 2021-11-15 16:12:36-->\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OkvfbALJUqfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2CbzhqN1UqjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пункт 2. Извлечение предложений из корпусов **Corus**."
      ],
      "metadata": {
        "id": "cN45W9sKjy8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### А. Достать тексты из корпусов"
      ],
      "metadata": {
        "id": "IBoMsPngw37f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install corus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_SB_9zFcQpc",
        "outputId": "621f3c8c-c700-46b3-c7f3-e22601cceb29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting corus\n",
            "  Downloading corus-0.10.0-py3-none-any.whl (83 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/83.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: corus\n",
            "Successfully installed corus-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соберу предложения из корпуса Ленты ру v1.0  и Риа Новости - чтобы хоть немного разные источники были представлены.  "
      ],
      "metadata": {
        "id": "PCu9OTorkhvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Всё для корпуса Lenta.ru v1.0:**"
      ],
      "metadata": {
        "id": "vBBvc3p1wC6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_lenta"
      ],
      "metadata": {
        "id": "wqX9v5lJb4zv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXEGjorOnf5g",
        "outputId": "2ef67931-7de4-4add-f723-ba05d03de8f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-07 02:44:57--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231207T024457Z&X-Amz-Expires=300&X-Amz-Signature=864bd427ba732bf73bc98812e13382924839c53010a1320d0aec0cdc1005d5a8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-07 02:44:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231207%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231207T024457Z&X-Amz-Expires=300&X-Amz-Signature=864bd427ba732bf73bc98812e13382924839c53010a1320d0aec0cdc1005d5a8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz.1’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  78.5MB/s    in 5.7s    \n",
            "\n",
            "2023-12-07 02:45:03 (88.2 MB/s) - ‘lenta-ru-news.csv.gz.1’ saved [527373240/527373240]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_news = 'lenta-ru-news.csv.gz'\n",
        "records_news = load_lenta(path_news)"
      ],
      "metadata": {
        "id": "FFqYgL2xb4_F"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(records_news)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1BqpSwypym3",
        "outputId": "9bf2aa32-6f9d-4653-8e36-cfd2d8662563"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LentaRecord(\n",
              "    url='https://lenta.ru/news/2018/12/14/cancer/',\n",
              "    title='Названы регионы России с\\xa0самой высокой смертностью от\\xa0рака',\n",
              "    text='Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.',\n",
              "    topic='Россия',\n",
              "    tags='Общество',\n",
              "    date=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Всё для корпуса Риа Новости:**"
      ],
      "metadata": {
        "id": "s1md7tHeuhaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/RossiyaSegodnya/ria_news_dataset/raw/master/ria.json.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb5bcM8euxDb",
        "outputId": "efe7821d-5b8c-414b-dfcc-83faf8920a79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-07 02:32:51--  https://github.com/RossiyaSegodnya/ria_news_dataset/raw/master/ria.json.gz\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://media.githubusercontent.com/media/RossiyaSegodnya/ria_news_dataset/master/ria.json.gz [following]\n",
            "--2023-12-07 02:32:51--  https://media.githubusercontent.com/media/RossiyaSegodnya/ria_news_dataset/master/ria.json.gz\n",
            "Resolving media.githubusercontent.com (media.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1025015063 (978M) [application/octet-stream]\n",
            "Saving to: ‘ria.json.gz’\n",
            "\n",
            "ria.json.gz         100%[===================>] 977.53M   259MB/s    in 3.6s    \n",
            "\n",
            "2023-12-07 02:33:11 (270 MB/s) - ‘ria.json.gz’ saved [1025015063/1025015063]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_ria\n",
        "\n",
        "path_ria = 'ria.json.gz'\n",
        "records_ria = load_ria(path_ria)\n",
        "next(records_ria)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuaWxGc1ubTn",
        "outputId": "5af20e1d-6985-43cc-f3ab-8f7ce04defb0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RiaRecord(\n",
              "    title='большинство детей, которых пытались увезти в сша из гаити, не сироты',\n",
              "    prefix='москва, 31 янв - риа новости.',\n",
              "    text='большая часть из 33 детей, которых граждане сша пытались вывезти из гаити в организованный в доминиканской республике приют, не являются сиротами, сообщает в воскресенье агентство франс пресс со ссылкой на заявление представителя международной организации \"детские деревни sos\" (sos children\\'s village), оказывающей помощь детям, оставшимся без родителей\\nкак заявила агентству патрисия варгас (patricia vargas), курирующая программы \"детских деревень sos\" в центральной америке, мексике и на карибах, поговорив с детьми она выяснила, что родители многих из них живы. некоторые дети смогли назвать свои домашние адреса и номера телефонов, что дает возможность связаться с их родителями.\\nв это воскресенье гаитянская полиция задержала десятерых граждан сша, подозреваемых в попытке без разрешения вывезти более 30 детей в доминиканскую республику.\\nпредставитель баптистской церкви в городе меридиан американского штата айдахо шон лэнкфорд (sean lankford) заявил, что задержанные прибыли на гаити в составе группы, помогающей детям, которые остались без родителей после разрушительного землетрясения 12 января.\\nлэнкфорд также сообщил, что в числе задержанных его дочь и жена, и они думали, что у них имеются все необходимые документы, позволяющие вывезти детей в организованный в доминиканской республике приют.\\nв настоящее время все эти дети, за исключением маленькой девочки, страдающей от истощения, которая была госпитализирована, находятся в благотворительном центре организации в городе круа-де-букет (croix des bouquets), расположенном в 12 километрах к северо-востоку от столицы гаити порт-о-пренса.\\nпо словам варгас, точный возраст малышки не известен, врачи полагают, что ей около 7 месяцев.\\nцентр \"детских деревень sos\" на гаити юридически не является сиротским приютом и не отдает детей на усыновление.\\nранее гаитянские интернет-ресурсы сообщали, что за  детьми, оставшимися сиротами после землетрясения, охотятся педофилы и торговцы  людьми >>\\nкак отмечает франс пресс, после разгула стихии на гаити были установлены новые правила усыновления, согласно которым премьер-министр страны жан-макс бельрив должен лично разрешить вывоз сирот. целью подобных мер является пресечение попыток незаконного вывоза детей для преступных целей в условиях хаоса, царящего в стране после разгула стихии.\\nпо данным ответственных лиц на гаити, тысячи детей могли быть разлучены с родителями или лишиться их в результате двух землетрясений магнитудой 7 и 5,9, произошедших у побережья этого островного государства 12 января.'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "dmxSNtklTRsc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEwKQweuTRuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WIyyGd1OTRxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jhh-Ky-7TR0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Б. Достать все формы слов"
      ],
      "metadata": {
        "id": "UBHMFucaxAo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Насколько я понимаю, нам надо достать все из этих слов во всех формах, так что сначала найдем все возможные их формы, чтобы запустить поиск."
      ],
      "metadata": {
        "id": "pXsKMI6FwKXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pymorphy2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs3oR83ExUIg",
        "outputId": "91874e42-8c0c-44f3-b30e-f929e17d08a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/55.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=e079f37557378981eca0ea2a3ccfa0477d68b9bf5b4295ce4027e31ce59d9f42\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "fWCQO0XVxKM0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_words = ['лук', 'коса', 'замок', 'кран', 'язык']"
      ],
      "metadata": {
        "id": "GULu4U2FxzDS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_forms = []\n",
        "for word in list_of_words:\n",
        "  p = morph.parse(word)[0]\n",
        "  list_of_forms += ([x.word for x in p.lexeme])"
      ],
      "metadata": {
        "id": "SGBRIYUXyUa7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_forms[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lV1DTCGque0",
        "outputId": "e806360f-8004-4a80-b45e-cedffd51f0dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['лук',\n",
              " 'лука',\n",
              " 'луку',\n",
              " 'луку',\n",
              " 'лук',\n",
              " 'луком',\n",
              " 'луке',\n",
              " 'луки',\n",
              " 'луков',\n",
              " 'лукам']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опыт показал, что эта форма очень мешает в следующем шаге"
      ],
      "metadata": {
        "id": "wa9Mh8teKOZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list_of_forms))\n",
        "list_of_forms.remove('кос')\n",
        "print(len(list_of_forms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqdM0oYJwxH",
        "outputId": "7cfed93c-bfa7-448a-b21c-91933fcff13b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собрали разные формы"
      ],
      "metadata": {
        "id": "x2KTuRudyyEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### В. Достать подходящие предложения"
      ],
      "metadata": {
        "id": "8Ac23xIjy2l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []"
      ],
      "metadata": {
        "id": "foKx-_vNxd58"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for record in records_news:\n",
        "    text = record.text.split(\".\")\n",
        "    for sentence in text:\n",
        "      if any(form in sentence.lower() for form in list_of_forms):\n",
        "        sentences.append(sentence)"
      ],
      "metadata": {
        "id": "YdzjyIz6z5CY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4RhHyO1I-Dm",
        "outputId": "913034ef-fb29-4c21-db33-1da9a2f41ce6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48761"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for record in records_ria:\n",
        "    text = record.text.replace('\\n', \" \").split(\".\")\n",
        "    for sentence in text:\n",
        "      if any(form in sentence.lower() for form in list_of_forms):\n",
        "        sentences.append(sentence)"
      ],
      "metadata": {
        "id": "vvlCOIO9JG8G"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmApL7Is0B31",
        "outputId": "91f5c5ec-976e-4c2a-a570-6d4fb2ff085d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179618"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ура, собрали мощное количество предложений. (Сохраняем, чтобы не переделывать)"
      ],
      "metadata": {
        "id": "7-LlLzPGMApU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"sentences.txt\", \"w\") as output:\n",
        "    output.write(str(sentences))"
      ],
      "metadata": {
        "id": "Jh7cUkwBNDE0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Пункт 3. *Разметка*!"
      ],
      "metadata": {
        "id": "iQr5fuebMIi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### А. Адаграм"
      ],
      "metadata": {
        "id": "EkMh1D08WUZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/lopuhin/python-adagram.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhAITgl6I-6N",
        "outputId": "5b839737-03ae-4cc2-a29d-4663aafd9f02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/lopuhin/python-adagram.git\n",
            "  Cloning https://github.com/lopuhin/python-adagram.git to /tmp/pip-req-build-d8bcuqtb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lopuhin/python-adagram.git /tmp/pip-req-build-d8bcuqtb\n",
            "  Resolved https://github.com/lopuhin/python-adagram.git to commit cf3639f10d6a1efbcb602f45a1da89ef55ce5794\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (3.0.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.9 in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adagram==0.0.1) (1.16.0)\n",
            "Building wheels for collected packages: adagram\n",
            "  Building wheel for adagram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adagram: filename=adagram-0.0.1-cp310-cp310-linux_x86_64.whl size=686349 sha256=a1cdc1fe0ba388c3a2be40106c49fc87a6c4015ba335d7a515b96f17a9a8d6b3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bqdd4od4/wheels/88/8b/fc/291709600177e98c9bba397433476b87d894ca506e78302432\n",
            "Successfully built adagram\n",
            "Installing collected packages: adagram\n",
            "Successfully installed adagram-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import adagram"
      ],
      "metadata": {
        "id": "w7VoG8kJI_CF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-3uzVtfGWT1A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "stops = set(stopwords.words('russian'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HF_dUj-WWZG",
        "outputId": "a4002ed0-6fa9-4171-fe8e-38ae008cf2c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl \"https://s3.amazonaws.com/kostia.lopuhin/all.a010.p10.d300.w5.m100.nonorm.slim.joblib\" > /content/drive/MyDrive/all.a010.p10.d300.w5.m100.nonorm.slim.joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9rNl6gBWWb8",
        "outputId": "d051ed3d-2608-402f-daf6-3a799000db31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/drive/MyDrive/all.a010.p10.d300.w5.m100.nonorm.slim.joblib: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T57E85EKWWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Б. ELMo + кластеризация просто KMeans"
      ],
      "metadata": {
        "id": "a7XVfCslMQ9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Упси как много ворнингов"
      ],
      "metadata": {
        "id": "QErhNU8RQpRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install allennlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGUdvLmrL_vq",
        "outputId": "ea4b89a6-b111-46a2-da41-f63da6860468"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Downloading allennlp-2.10.1-py3-none-any.whl (730 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<1.13.0,>=1.10.0 (from allennlp)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.14.0,>=0.8.1 (from allennlp)\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached-path<1.2.0,>=1.1.3 (from allennlp)\n",
            "  Downloading cached_path-1.1.6-py3-none-any.whl (26 kB)\n",
            "Collecting fairscale==0.4.6 (from allennlp)\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.8.1)\n",
            "Collecting spacy<3.4,>=2.1.0 (from allennlp)\n",
            "  Downloading spacy-3.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.4 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.23.5)\n",
            "Collecting tensorboardX>=1.2 (from allennlp)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from allennlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.10/dist-packages (from allennlp) (4.66.1)\n",
            "Requirement already satisfied: h5py>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.9.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from allennlp) (1.11.4)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.10/dist-packages (from allennlp) (7.4.3)\n",
            "Collecting transformers<4.21,>=4.1 (from allennlp)\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.96 (from allennlp)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock<3.8,>=3.3 (from allennlp)\n",
            "  Downloading filelock-3.7.1-py3-none-any.whl (10 kB)\n",
            "Collecting lmdb>=1.2.1 (from allennlp)\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=8.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (10.1.0)\n",
            "Collecting termcolor==1.1.0 (from allennlp)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wandb<0.13.0,>=0.10.0 (from allennlp)\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.0.16 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.19.4)\n",
            "Collecting dill>=0.3.4 (from allennlp)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting base58>=2.1.1 (from allennlp)\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting sacremoses (from allennlp)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (0.9.0)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from allennlp) (3.20.3)\n",
            "Requirement already satisfied: traitlets>5.1.1 in /usr/local/lib/python3.10/dist-packages (from allennlp) (5.7.1)\n",
            "Collecting jsonnet>=0.10.0 (from allennlp)\n",
            "  Downloading jsonnet-0.20.0.tar.gz (594 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rich<13.0,>=12.1 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0 (from cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading boto3-1.33.9-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<3.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from cached-path<1.2.0,>=1.1.3->allennlp) (2.8.0)\n",
            "Collecting huggingface-hub>=0.0.16 (from allennlp)\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.0.16->allennlp) (23.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->allennlp) (2023.6.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=6.2.5->allennlp) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->allennlp) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.1->allennlp) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.0.9)\n",
            "Collecting thinc<8.1.0,>=8.0.14 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading thinc-8.0.17-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (659 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.7.11)\n",
            "Collecting wasabi<1.1.0,>=0.9.1 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (2.0.10)\n",
            "Collecting typer>=0.4.1 (from allennlp)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (6.4.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 (from spacy<3.4,>=2.1.0->allennlp)\n",
            "  Downloading pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.4,>=2.1.0->allennlp) (3.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.14.0,>=0.8.1->allennlp) (9.4.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers<4.21,>=4.1->allennlp)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting GitPython>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting shortuuid>=0.5.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (1.16.0)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting botocore<1.34.0,>=1.33.9 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading botocore-1.33.9-py3-none-any.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.9.0,>=0.8.2 (from boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.17.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.6.0)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0,>=12.1->cached-path<1.2.0,>=1.1.3->allennlp) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.4,>=2.1.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.9->boto3<2.0,>=1.0->cached-path<1.2.0,>=1.1.3->allennlp) (2.8.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb<0.13.0,>=0.10.0->allennlp)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.61.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (1.5.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage<3.0,>=1.32.0->cached-path<1.2.0,>=1.1.3->allennlp) (0.5.1)\n",
            "Building wheels for collected packages: fairscale, termcolor, jsonnet, pathtools\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307222 sha256=0c2eb891bdfcb99aed178f50e02c65bc81bc9f2c9b292ace46b9d6b2f19c650b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/58/3d/e114952ab4a8f31eb9dae230658450afff986b211a5b1f2256\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=4ec3ccac9d95e8a82034dfaeddea43baaaab575cd8fed6db75180056d0b7f5b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/49/46/1b13a65d8da11238af9616b00fdde6d45b0f95d9291bac8452\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.20.0-cp310-cp310-linux_x86_64.whl size=6406867 sha256=72ad82ebcd2b13ea5b5c9fdf9286ae1609703a0b10e03baa4e48304be0a6c4b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/0d/6b/5467dd1db9332ba4bd5cf4153e2870c5f89bb4db473d989cc2\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8793 sha256=92ad88ff9efc57f48ccb5382bb0b4d295cf6c632c6ba015cb35e4f1f7658c36c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built fairscale termcolor jsonnet pathtools\n",
            "Installing collected packages: wasabi, tokenizers, termcolor, sentencepiece, pathtools, lmdb, jsonnet, commonmark, typer, torch, tensorboardX, smmap, shortuuid, setproctitle, sentry-sdk, sacremoses, rich, pydantic, jmespath, filelock, docker-pycreds, dill, base58, torchvision, thinc, huggingface-hub, gitdb, fairscale, botocore, transformers, spacy, s3transfer, GitPython, wandb, boto3, cached-path, allennlp\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.3.0\n",
            "    Uninstalling termcolor-2.3.0:\n",
            "      Successfully uninstalled termcolor-2.3.0\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.12\n",
            "    Uninstalling thinc-8.1.12:\n",
            "      Successfully uninstalled thinc-8.1.12\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.3.3 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.40 allennlp-2.10.1 base58-2.1.1 boto3-1.33.9 botocore-1.33.9 cached-path-1.1.6 commonmark-0.9.1 dill-0.3.7 docker-pycreds-0.4.0 fairscale-0.4.6 filelock-3.7.1 gitdb-4.0.11 huggingface-hub-0.10.1 jmespath-1.0.1 jsonnet-0.20.0 lmdb-1.4.1 pathtools-0.1.2 pydantic-1.8.2 rich-12.6.0 s3transfer-0.8.2 sacremoses-0.1.1 sentencepiece-0.1.99 sentry-sdk-1.38.0 setproctitle-1.3.3 shortuuid-1.0.11 smmap-5.0.1 spacy-3.3.3 tensorboardX-2.6.2.2 termcolor-1.1.0 thinc-8.0.17 tokenizers-0.12.1 torch-1.12.1 torchvision-0.13.1 transformers-4.20.1 typer-0.4.2 wandb-0.12.21 wasabi-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Применяем"
      ],
      "metadata": {
        "id": "iShkFj8wQv6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Iy9uICnyLs4P",
        "outputId": "b6aacdeb-f722-4fff-fca4-258873e7e826"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-47e967ea75be>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmoEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp.commands.elmo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15X4zrqsRGgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOb7p1u7RGjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZEr-KzuLs-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}